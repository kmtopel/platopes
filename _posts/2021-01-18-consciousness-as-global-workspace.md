---
layout: post
categories: [philosophy of mind, neuroscience]
title: Consciousness as a Data Structure
thesis: Consciousness is a data structure that allows information exchanged between brain and world to be represented as one continuous process.
---
There's a concept featured in many philosophical thought experiments of the "philosophical zombie" – a human being who
looks, behaves, and communicates like a typical human, but has no subjective inner experience. In many definitions of consciousness, and in the definition(s) I prefer, this aspect of "subjective inner experience" is the main target of the term "consciousness" and constitutes the core of the enigma that we seek to explain. The philosophical zombie is a complete fiction, such a being doesn't exist (I hope), yet it's meant to highlight the question "what is consciousness for?" It seems obvious to us in our subjective encounters with reality that consciousness is useful for everything we are doing and that we wouldn't be able to function without it. However, as we further understand the anatomy and physiology of the brain – what tasks each structure performs, how networks of neurons process information, how the brain interfaces and communicates with the rest of the body, and so on – it becomes clear that many processes already function perfectly fine without consciousness and it's not much of a stretch to assume that the brain mechanisms we associate with "consciousness" could function without the subjective inner experience as well. Therefore, it seems completely enigmatic why some brain functions have subjective experience accompanying them and others do not when both functions use the same types of structures to operate.

To make sense of some terms I may or may not use in articulating an idea that's been floating around my dome lately, I've created the following masterpiece:

<img class="img-fluid" src="/assets/images/mind_brain_world.jpg">

The arrows represent causation, meaning the thing pointed to owes its existence or current properties to the thing pointing at it. There are three entities that we're trying to understand in a common framework: (1) brain, (2) consciousness, and (3) the external world. To start with the interactions between brain and world, Realism is the idea that strikes many of our 21st century educated minds as commonsensical – namely, there's an external world out there independent of our minds that enabled by our sense organs is perceived by our minds. Idealism flips that causal arrow the other direction and states that the external world is caused by our minds. To quote the philosopher George Berkeley, "to be is to be perceived" and what he means by this is as follows:
> ...what do we perceive besides our own ideas or sensations; and is it not plainly repugnant that any one of these or any combination of them should exist unperceived?

Phenomenology and Transcendental Idealism, the metaphysical theory developed by Immanuel Kant, both stipulate, in their own ways, a reality that emerges from the interplay of the external world and the subject's encounter with that world. Phenomenology wants to fixate our attention on our pre-theoretical encounter with the world, the world before we divide it into subject and object, the world <i>as we directly and immediately encounter it in our own experience</i>.

Dualism and epiphenomenalism are just two of <i>many</i> views that seeks to explain the interaction between consciousness and brain. I mention them in my cute little picture, because they are common and often presupposed in conversations about consciousness. Dualism sees consciousness (or mind/mental stuff) as a separate substance from the brain. The main problem with this view is trying to reconcile how these two substances interact, though it's stipulated by some that both can exert a causal influence on the other <i>somehow</i>. It's conceivable that a dualistic approach to brain and consciousness could go without drawing a causal arrow at all, meaning that while these two substances, one mental and one physical, are tightly (maybe even perfectly) correlated with each other, one does not influence the other and they remain in separate spheres of reality. The philosopher and mathematician Bertrand Russell posited the idea of Neutral Monism, which states that while we are conceptually limited to explaining both the physical and mental as two different types of substances, in reality they both partake of an shared underlying substance that we don't have direct access to and/or can't fit into a neat conceptual package.  Epiphenomenalism is more a theory about which way the causal arrow points in matters of brain and consciousness, and in this theory brain influences mind but not vice versa – consciousness is just something the brain incidentally secretes.

Intuitively, I'm drawn to the Realist thesis that there is an external world independent of our perception of it, though I'm humble enough to admit that this external world might be very different from the world that is presented to us via our senses.  It's conceptually impossible to imaginatively construct a world devoid of a perceiving subject, because the very act of doing so imports the perceiving subject right back in the picture and this is why Idealism, upon reflection, has had an appeal for many. Phenomenology is another school of thought that interests me, because it emphasizes the "intentionality" of consciousness. Intentionality in the phenomenological sense refers to the "aboutness" of consciousness – that is, consciousness is always <i>about</i> something; we're always conscious of something in the world; consciousness never just appears in a pure form detached from some referent. In regards to this particular point, I often recall a passage in the book <i>Neither Brain nor Ghost: A Nondualist Alternative to the Mind-Brain Identity Theory</i> by philosopher Teed Rockwell where he asks "where does the mind stop and the world begin?" It's an interesting question, because we often assume, given the dualistic legacy of Descartes, that the mind is somehow inside the brain, though as the philosopher and cofounder of Calculus Gottfried Leibniz pointed out, and I paraphrase, if we were to expand the brain to the size of a building where we could walk around inside of it, there'd be no location in that building in which we'd come across anything that resembles what we refer to as the "mind" or "consciousness." Rockwell's question points out that mind is better conceptualized as a dynamic continuum between brain and environment.

Given the analogies that exist between the brain and computers, especially the fact that both entities can be conceived of as information-processors, as well as hypotheses about the objective physical world emerging from a substrate of information, perhaps more concepts from Computer Science could be imported into the philosophical/neuroscientific discussions about the nature of consciousness. As the title of this post suggests, the idea of a Data Structure is what I have in mind. Per Wikipedia, the following is a succinct definition of a Data Structure in the Computer Science sense of the term:

>In computer science, a data structure is a data organization, management, and storage format that enables efficient access and modification. More precisely, a data structure is a collection of data values, the relationships among them, and the functions or operations that can be applied to the data.

I find this concept interesting in this context, because consciousness as a dynamic between brain and environment relies on the notion of information exchange. Could there be such data structures in the world such that environmental information processed in a certain way by a central nervous system gives rise to the emergent property of consciousness? Consider the hypothetical scenario in which neuroscientists and engineers collaborate and construct a robot endowed with all the features a human being has. This robot even has a collection of neurons in its artificial brain comparable to number of neurons in the human brain, and they are all equally as well connected. Upon booting up this robot, it behaves and interacts with the world in a manner identical to human beings. The question then arises "is it conscious?" Now the burden is on the scientists to find a definitive way to prove that it either is or isn't conscious, because we are morally-obligated to treat this robot in certain ways if it is conscious and has the capacity to suffer. What could function as a definitive scientific test of whether or not a being is conscious? This brings up the important point that we only have access to our own individual consciousnesses and we all just <i>assume</i> everyone else is conscious the way we are. I'm not saying we should all live in the solipsistic nightmare in which we are the only being in this world that's conscious, since we can't yet prove in a conclusive scientific way that others are conscious. I'm merely suggesting that our "proof" is a pre-theoretical intuitive one. If we have feel compassion for some being, are able to project ourselves into another's circumstances and imagine life from their perspective, and empathize with another's experiences, this is sufficient for us to assume consciousness is also present in that being. And all of these experiences of empathy and perspective-taking are pre-theoretical and not cognitive in the sense of being constructed by some conscious reflective process. Perhaps that's also what will occur if robots exist among us. If a being is capable of activating our theory of mind and evoking a sense of empathy, maybe debate about it being a bearer of consciousness will be irrelevant.

Forgive the rant, but I felt like that thought experiment was a useful illustration of the complexities of both defining and proving the existence of consciousness in a scientific way. What I want to emphasize in my hypothesis of consciousness as a data structure is the notion that consciousness is better conceived as a process and continuum rather than a property. Our brains evolved via the process of natural selection in which the environment selected for the brains that enabled our species to survive long enough to reproduce successfully. Therefore, it makes sense that consciousness is intentional in the phenomenological sense, because the many of the brain's primary tasks involve interfacing with the environment. Data Structures are relevant, because the brain's representations of the environment are very selective in regards to information and there needs to be an efficient and organized way of making sense of the environment – the plethora of information has to be compressed into a useable form. The amount of neurons in the retina testifies to the amount of preprocessing that occurs before information makes its way deeper into the brain. There's a lot of information to process via our senses and our brains filter out only that which is useful to us. No doubt there's useless information that makes its way past those filters, because only information that would detract from our ability to survive and reproduce would've prevented our particular set of perceptual filters to evolve. These perceptual filters don't conceal reality from us or <i>mis</i>represent it, because a false picture of reality wouldn't facilitate our survival goals. Many want to suggest that our mental representations are completely heterogeneous with the external world, but in my view a compressed picture of the environment doesn't suggest a false or inaccurate view because that information that passes the perceptual filters still lies on a continuum between brain and world, and it's my intuition that this brain-world continuum somehow constitutes consciousness.

But like I said, this is a purely speculative hypothesis that I've barely begun developing, and it might be a completely confused and nonsensical idea.
